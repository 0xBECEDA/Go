* Интро
Идея простая: переписать свой старый консольный мессенджер с си на
го. При этом добавить шифрование, поддержку множества клиентов и какойто
интерфейс.

* Механизм работы

Нужно организовать пересылку сообщения от конкретного клиента к
конкретному клиенту. Т.е. у каждого клиента - зарегистрированного
пользователя -  должны быть уникальный id, который не будет меняться от
подключения к подключению.

Сервер будет хранить у себя хэш-таблицу, где ключ - это уникальный
неменяющийся id клиента, а значение - ~conn~ этого клиента. Поэтому
сервер сможет легко находить соединение с клиентом, которому предназначен пакет

Структура пакета клиента для отправки:
- id юзера, ~который отправляет~
- id юзера, ~которому отрпавляют~
- буфер, в котором содержится сообщение
- статус отправки сообщения

Клиент работает в 2 потока: один принимает сообщения, другой отправляет.

[TODO:gmm] Возможно организовать очередь сообщений: все пакеты на
отправку будут находиться в единой очереди. Каждый раз, когда клиент
хочет отправить сообщениеновому юзеру - открыть новый чат - открываются 2
новых потока: один на отправку, другой на принятие сообщений. Когда
клиент хочет отправить кому-то сообщение, пакет кладется в общую очередь
сообщений (возможно, очередь будет представлять собой канал, чтоб
избежать мьютексов), а любой свободный на отправку поток будет отправлять
пакет.

Структура соединения на сервере:
- id клиента - по умолчанию -1
- его структура ~conn~, по умолчанию nil

[TODO:gmm] В идеале, при регистрации нового пользователя, сервер сразу получает его
уникальный id, записывает его в структуру, а затем ждет, когда клиент
подключится к нему, дополняет структур его ~conn~, а затем из id и conn
создает новую запись для хэш-таблицы.

Таким образом, у нас должен быть массив "неполных" структур, где есть
только id новых клиентов, но еще нет соединений с ними. Когда соединение
появляется, формирутеся запись в хэш-таблице, а структура из массива
структур очищается. Массив и хэш0таблицу придется блокировать мьютексом
или чем-то еще, поскольку это разделяемый ресурс.

Чтоб у сервера был полный набор айдиников существующих клиентов, должна
быть база данных существующих клиентов. Тогда при запуске мессенджера, эта база данных
будет посылаться серверу, сервер будет ее у себя распаковывать и ждать
соединений от клиентов. Не знаю, насколько это оптимально.

Как будет работать сейчас, тестовая модель:
Базы данных клиентов нет.
Уникальный id клиента вводится самим пользователем при запуске клиента -
параметр командной строки. Т.е. id может меняться от запуска к запуску.

На стороне сервера есть массив структур соединений. Есть указатель на ближайшую свободную
структуру.

Клиент устанавливает соединение. Сервер получает его ~conn~ - но еще не
знает, какой у клиента уникальный ~id~, потому что первый пакет до сих
пор не пришел. Соединение ~conn~ записывается в массив структур,
указатель на ближайшую доступную структуру для записи сдвигается. Клиент
шлет первый пакет: сервер разбирает этот пакет, читает ~id~ клиента и
ищет структуру клиента по его ~conn~. Вписывает ~id~ в структуру. Так мы
связываем уникальный id клиента и его соединение. Таким образом, когда
какой-то другой клиент захочет отправить сообщение этому клиенту, мы
найдем его по его id и отправим в его соединение сообщение.

В случае если сервер не смог отправить сообщение от клиента к клиенту -
например, принимающая сторона еще не подсоединилась или нет ее id, то
сервер отправляет отправляющей стороне ее же сообщение со статусом
failed - меняет поле в структуре пакета. Если клеинт принимает такое
сообщение, то этот пакет будет помещен в конец глобальной очереди
сообщений для повторной отправки в будущем.

* Реализация идей, изложенных выше

** Пункт первый
- создать структуру пакета на стороне клиента
- создать функцию на стороне клиента, которая будет разбирать, с каким
  статусом пришло сообщение от сервера: если со статусом ~failed~, то
  напечатать сообщение, что пакет не был доставлен адресату. В противном
  случае напечатать полученное сообщение

На этом этапе сервер получает пакет от клиента, меняет у него статус и
возвращает пакет клиенту.

Проблема в том, что методы ~read()~ и ~write()~ для чтения и записи в
соединение принимают в качестве буфера только слайс.

Поэтому структуру пакета нужно сериализовать для отправки, а потом
десериализовать для парсинга.
